{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krutarth\\Desktop\\Datasets\\greyatom_customerNLP\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\Krutarth\\Desktop\\Datasets\\greyatom_customerNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_data.csv')\n",
    "data.drop(columns=['MID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7am everyday</td>\n",
       "      <td>reminders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chocolate cake</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>closed mortice and tenon joint door dimentions</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train eppo kelambum</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yesterday i have cancelled the flight ticket</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          message   category\n",
       "0                                    7am everyday  reminders\n",
       "1                                  chocolate cake       food\n",
       "2  closed mortice and tenon joint door dimentions    support\n",
       "3                             train eppo kelambum     travel\n",
       "4    yesterday i have cancelled the flight ticket     travel"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.category.replace({'casual':0,\n",
    "  'food':1,\n",
    "  'movies':2,\n",
    "  'nearby':3,\n",
    "  'other':4,\n",
    "  'recharge':5,\n",
    "'reminders':6,\n",
    " 'support':7,\n",
    " 'travel':8}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = data.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower--done\n",
    "#tokenize--done\n",
    "#stop words removal--done\n",
    "#lemmatize--done\n",
    "#join again\n",
    "#tfidif vectorize\n",
    "#svm, regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_smol = message.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_tokenize = message_smol.apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          [7am, everyday]\n",
       "1                                        [chocolate, cake]\n",
       "2        [closed, mortice, and, tenon, joint, door, dim...\n",
       "3                                  [train, eppo, kelambum]\n",
       "4        [yesterday, i, have, cancelled, the, flight, t...\n",
       "                               ...                        \n",
       "40654    [if, i, add, money, will, it, have, any, expir...\n",
       "40655                                        [receipes, ?]\n",
       "40656                       [what, is, this, insurance, ?]\n",
       "40657                          [i, am, unable, to, search]\n",
       "40658                        [it, 's, a, good, experience]\n",
       "Name: message, Length: 40659, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '7gh'\n",
    "any([i.isdigit() for i in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_num = []\n",
    "for message in message_tokenize:\n",
    "    message_word = []\n",
    "    for word in message:\n",
    "        if any([i.isdigit() for i in word]) == True:\n",
    "            message_word.append('number')\n",
    "        else:\n",
    "            message_word.append(word)\n",
    "    message_num.append(message_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english') + list(punctuation)+['..','...'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_stop = []\n",
    "for message in message_num:\n",
    "     message_stop.append([i for i in message if i not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "message_lemmatize=[]\n",
    "for message in message_stop:\n",
    "    message_lemmatize.append([lemmatizer.lemmatize(i) for i in message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_join = []\n",
    "for message in message_lemmatize:\n",
    "    message_join.append(' '.join(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "vector_tfidf = tfidf.fit_transform(message_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(random_state=0, kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(vector_tfidf, data.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krutarth\\Desktop\\Datasets\\greyatom_customerNLP\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\Krutarth\\Desktop\\Datasets\\greyatom_customerNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_message = test.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_message_smol = test_message.apply(lambda x: x.lower())\n",
    "\n",
    "test_message_tokenize = test_message_smol.apply(lambda x: word_tokenize(x))\n",
    "\n",
    "test_message_num = []\n",
    "for test_message in test_message_tokenize:\n",
    "    test_message_word = []\n",
    "    for word in test_message:\n",
    "        if any([i.isdigit() for i in word]) == True:\n",
    "            test_message_word.append('number')\n",
    "        else:\n",
    "            test_message_word.append(word)\n",
    "    test_message_num.append(test_message_word)\n",
    "    \n",
    "test_message_stop = []\n",
    "for test_message in test_message_num:\n",
    "     test_message_stop.append([i for i in test_message if i not in stop_words])\n",
    "\n",
    "test_message_lemmatize=[]\n",
    "for test_message in test_message_stop:\n",
    "    test_message_lemmatize.append([lemmatizer.lemmatize(i) for i in test_message])\n",
    "    \n",
    "test_message_join = []\n",
    "for test_message in test_message_lemmatize:\n",
    "    test_message_join.append(' '.join(test_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf = tfidf.transform(test_message_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svc.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.columns = ['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krutarth\\Desktop\\Datasets\\greyatom_customerNLP\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\Krutarth\\Desktop\\Datasets\\greyatom_customerNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
